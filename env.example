# LLM Provider Configuration (Priority: OPENAI_API_KEY > GOOGLE_API_KEY > GROQ_API_KEY)
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Google/Gemini Configuration  
GOOGLE_API_KEY=your_google_api_key_here

# Groq Configuration (fallback)
GROQ_API_KEY=your_groq_api_key_here

# Model Configuration (unified)
LLM_MODEL=gpt-4o-mini  # Examples: gpt-4o-mini, gemini-2.0-flash, llama3-8b-8192

# Legacy Groq Model (for backward compatibility)
GROQ_MODEL=meta-llama/llama-guard-4-12b

# Application Settings
TEMPERATURE=0.7
MAX_TOKENS=5000
TOKENIZERS_PARALLELISM=true
# Vector Database Settings
VECTOR_DB_PATH=./data/vector_db
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Document Processing
DOCUMENTS_PATH=./documents

# Conversation Memory Settings
MAX_CONVERSATION_TOKENS=4000
SUMMARIZATION_THRESHOLD=0.8
ENABLE_CONVERSATION_MEMORY=true

# Document Retrieval Settings
RETRIEVAL_TOP_K=5
RETRIEVAL_THRESHOLD=0.3
ENABLE_RETRIEVAL_DEBUG=false

# UI Settings
USER_PROMPT=You
GOODBYE_MESSAGE=Goodbye! Thanks for using RAG Sample.
WELCOME_MESSAGE=Welcome to RAG Sample! Ask me anything about your documents.

# Debug Settings
SHOW_PROMPT=0  # Set to 1 to display prompts being sent to LLM
